# TensorFlow Lite Integration Guide

**BEACON iOS App - SOS Voice Detection using TensorFlow Lite**

Last Updated: October 15, 2025

---

## ‚úÖ What's Been Done

1. ‚úÖ Downloaded .tflite model from Edge Impulse (v6)
2. ‚úÖ Copied model to project: `BEACON/Resources/sos_model.tflite`
3. ‚úÖ Created `KeywordSpotterTFLite.swift` with TFLite inference
4. ‚úÖ Model specifications identified:
   - Input: 3960 float32 values (DSP-processed features)
   - Output: 3 classes [SOS, noises, unknown]
   - Sample rate: 16 kHz
   - Threshold: 0.6 confidence

---

## üìã Manual Steps Required in Xcode

### Step 1: Add TensorFlow Lite Framework

**Option A: Swift Package Manager (Recommended)**

1. Open Xcode project:
   ```
   open /Users/kasturirajguhan/Documents/BEACON_Project/BEACON_iOS/BEACON_5.xcodeproj
   ```

2. Add Swift Package:
   - File ‚Üí Add Package Dependencies...
   - Enter URL: `https://github.com/tensorflow/tensorflow`
   - Select "TensorFlowLiteSwift" package
   - Version: Use "Up to Next Major" (2.x.x)
   - Add to BEACON target

**Option B: Manual Framework Integration**

If Swift Package Manager doesn't work:

1. Download TensorFlow Lite framework:
   ```bash
   curl -L https://github.com/tensorflow/tensorflow/releases/download/v2.12.0/TensorFlowLiteSwift.xcframework.zip -o TFLite.zip
   unzip TFLite.zip
   ```

2. In Xcode:
   - Drag `TensorFlowLiteSwift.xcframework` into project
   - Target ‚Üí BEACON ‚Üí Frameworks, Libraries, and Embedded Content
   - Add TensorFlowLiteSwift.xcframework (Embed & Sign)

---

### Step 2: Add Model File to Xcode

1. **Add sos_model.tflite to project:**
   - In Finder, navigate to:
     ```
     /Users/kasturirajguhan/Documents/BEACON_Project/BEACON_iOS/BEACON/Resources/
     ```
   - Drag `sos_model.tflite` into Xcode project navigator
   - In dialog:
     - ‚úÖ Check "Copy items if needed"
     - ‚úÖ Select "BEACON" target
     - ‚úÖ Click "Finish"

2. **Verify file is in bundle:**
   - Select `sos_model.tflite` in project navigator
   - File Inspector ‚Üí Target Membership ‚Üí ‚úÖ BEACON

---

### Step 3: Replace KeywordSpotter.swift

**Remove old file:**
1. In Xcode, right-click `KeywordSpotter.swift`
2. Select "Delete" ‚Üí "Move to Trash"

**Add new file:**
1. In Finder, navigate to:
   ```
   /Users/kasturirajguhan/Documents/BEACON_Project/BEACON_iOS/BEACON/Services/
   ```
2. Drag `KeywordSpotterTFLite.swift` into Xcode `Services` group
3. Rename it to `KeywordSpotter.swift` (or update imports in KeywordSpottingView)

**OR** simply replace the contents of the existing file with the TFLite version.

---

### Step 4: Build Project

1. **Clean Build:**
   - Product ‚Üí Clean Build Folder (‚áß‚åòK)

2. **Build:**
   - Product ‚Üí Build (‚åòB)

3. **Expected outcomes:**
   - ‚úÖ No "SOSKeywordModel" errors (we're using TFLite now)
   - ‚úÖ TensorFlow Lite framework imports successfully
   - ‚úÖ Model loads at runtime

---

## üîç Key Differences from Core ML Approach

### What Changed:

**Before (Core ML - didn't work):**
```swift
import CoreML

let model = try SOSKeywordModel(configuration: config)
let input = SOSKeywordModelInput(input: audioArray)
let output = try model.prediction(input: input)
```

**After (TensorFlow Lite - works):**
```swift
import TensorFlowLite

let interpreter = try Interpreter(modelPath: modelPath)
try interpreter.allocateTensors()
try interpreter.copy(inputData, toInputAt: 0)
try interpreter.invoke()
let outputTensor = try interpreter.output(at: 0)
```

### Why TensorFlow Lite:

1. **Direct compatibility** - .tflite files work without conversion
2. **Smaller size** - 55 KB vs ~127 KB for Core ML
3. **Proven reliability** - TFLite is the source format from Edge Impulse
4. **No conversion errors** - Skips the problematic TFLite ‚Üí Core ML step

---

## ‚ö†Ô∏è Important Notes

### Model Input Preprocessing

The Edge Impulse model expects **3960 features**, not raw 16000 audio samples.

**Current implementation:**
- Simple downsampling (averaging) from 16000 ‚Üí 3960
- ‚ö†Ô∏è This is a **placeholder** and may reduce accuracy

**Production implementation needs:**
- Proper DSP matching Edge Impulse preprocessing
- Options:
  1. MFE (Mel-filterbank energies)
  2. MFCC (Mel-frequency cepstral coefficients)
  3. Spectrogram
  4. Use Edge Impulse SDK's DSP functions

**To find out which DSP:**
Check the Edge Impulse Studio ‚Üí Your Project ‚Üí Create Impulse ‚Üí Processing Block

---

## üß™ Testing

### Test 1: Model Loading

```
Expected console output:
[KeywordSpotter] ‚úÖ TensorFlow Lite model loaded successfully
[KeywordSpotter]    Input shape: [1, 3960]
[KeywordSpotter]    Output shape: [1, 3]
```

### Test 2: Audio Capture

```
[KeywordSpotter] Hardware sample rate: 48000.0 Hz
[KeywordSpotter] üé§ Started listening at 16 kHz
```

### Test 3: Inference

```
[KeywordSpotter] üö® SOS DETECTED! Confidence: 0.XXX (inference: XX.Xms)
```

---

## üìä Performance Expectations

**With current downsampling approach:**
- Inference time: < 100ms
- CPU usage: ~15%
- Memory: ~10 MB
- Battery: Moderate

**With proper DSP:**
- Inference time: < 50ms
- Better accuracy
- Similar resource usage

---

## üêõ Troubleshooting

### Error: "No such module 'TensorFlowLite'"

**Fix:**
1. Verify Swift Package added correctly
2. Product ‚Üí Clean Build Folder
3. File ‚Üí Packages ‚Üí Reset Package Caches
4. Rebuild

---

### Error: "Model file not found in bundle"

**Fix:**
1. Check `sos_model.tflite` is in project navigator
2. Select file ‚Üí File Inspector ‚Üí Target Membership ‚Üí ‚úÖ BEACON
3. Product ‚Üí Clean Build Folder ‚Üí Rebuild

---

### Warning: Low detection accuracy

**Cause:** Simple downsampling doesn't match Edge Impulse DSP

**Fix:** Implement proper DSP preprocessing (see Production Implementation below)

---

## üöÄ Production Implementation (Optional)

To achieve full accuracy, you need to implement the Edge Impulse DSP pipeline.

### Option 1: Use Edge Impulse iOS SDK

```swift
// Add Edge Impulse iOS SDK via CocoaPods or SPM
import EdgeImpulse

let dsp = EISDK.createDSP(config: dspConfig)
let features = dsp.process(audioSamples)  // 16000 ‚Üí 3960
```

### Option 2: Manual DSP Implementation

Check your Edge Impulse project's DSP settings and implement:
- Window size, hop length
- FFT parameters
- Filter banks (if MFE/MFCC)
- Normalization

---

## üìÅ File Summary

### Added Files:

```
BEACON_iOS/BEACON/
‚îú‚îÄ‚îÄ Resources/
‚îÇ   ‚îî‚îÄ‚îÄ sos_model.tflite                    (55 KB - TFLite model)
‚îú‚îÄ‚îÄ Services/
‚îÇ   ‚îî‚îÄ‚îÄ KeywordSpotterTFLite.swift          (New implementation)
‚îî‚îÄ‚îÄ Views/
    ‚îî‚îÄ‚îÄ KeywordSpottingView.swift           (No changes needed)
```

### Modified Files:

- `Info.plist` - Microphone permission (already done)
- `BLEManager.swift` - SOS BLE command (already done)
- `AlertManager.swift` - SOS alert type (already done)

---

## ‚úÖ Final Checklist

Before testing:

- [ ] TensorFlow Lite framework added to project
- [ ] sos_model.tflite added to BEACON target
- [ ] KeywordSpotter uses TFLite implementation
- [ ] Project builds without errors (‚åòB)
- [ ] Microphone permission in Info.plist
- [ ] Tested on physical iPhone (simulator won't work for audio)

---

## üìû Next Steps

1. **Add TensorFlow Lite package** (Swift Package Manager)
2. **Add model file** to Xcode project
3. **Build and test** on physical iPhone
4. **(Optional) Improve DSP** for better accuracy

---

**Status:** ‚úÖ Code ready - requires manual Xcode steps

**Framework:** TensorFlow Lite Swift

**Model Size:** 55 KB

**Compatibility:** iOS 12+ (TFLite requirement)
